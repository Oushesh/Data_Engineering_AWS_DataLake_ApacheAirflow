export AIRFLOW_HOME= ~/Documents/Workspace/Data_Engineering_AWS_DataLake_ApacheAirflow/ETL_Pipeline/AirflowSession/
[core]
# The home folder for airflow
airflow_home = ~/Documents/Workspace/Data_Engineering_AWS_DataLake_ApacheAirflow/ETL_Pipeline/AirflowSession/

# The executor type
executor = SequentialExecutor

# The SQL Alchemy connection string for the metadata database
sql_alchemy_conn = postgresql+psycopg2://oushesh:12345@localhost:5432/airflow

# The directory where your DAGs are stored
dags_folder = ~/Documents/Workspace/Data_Engineering_AWS_DataLake_ApacheAirflow/ETL_Pipeline/AirflowSession/Dags

# The directory where Airflow should store logs
base_log_folder = ~/Documents/Workspace/Data_Engineering_AWS_DataLake_ApacheAirflow/ETL_Pipeline/AirflowSession/logs

# The Airflow webserver host
web_server_host = 0.0.0.0
web_server_port = 8080

# Enable or disable the DAG bag loading process
load_examples = False

# Enable or disable DAG serialization to the database
store_serialized_dags = True

# Enable or disable the use of a secure cookie for the web UI
cookie_secure = False

# Enable or disable the use of Cross-Site Request Forgery (CSRF) protection
csrf_enabled = True

[webserver]
# The number of workers for the web server
workers = 4

# The secret key used for signing cookies
secret_key = your_secret_key

[scheduler]
# The number of max active DAG runs per DAG
max_active_runs_per_dag = 16

# The interval at which the scheduler checks for new DAG runs
scheduler_job_heartbeat_sec = 5

# The amount of time to wait between consecutive scheduler job executions
scheduler_heartbeat_sec = 10

[operators]
# The default number of retries for task failures
default_task_retries = 3

# The amount of time to wait between task retries
default_retry_delay = 300

[smtp]
# SMTP server configuration for sending email
smtp_host = smtp.gmail.com
smtp_starttls = True
smtp_ssl = False
smtp_user = your_email@gmail.com
smtp_password = your_password
smtp_port = 587
smtp_mail_from = your_email@gmail.com

[logging]
# Airflow logging configuration
log_level = INFO
logging_config_class = airflow.config_templates.default_log_config.LOGGING_CONFIG
